{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following directory to the PYTHONPATH: d:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path   \n",
    "root_dir = str(Path().absolute().parent)\n",
    "\n",
    "if root_dir not in sys.path:\n",
    "    print(f\"Adding the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from recsys.config import settings\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CUSTOMER_DATA_SIZE': <CustomerDatasetSize.SMALL: 'SMALL'>,\n",
      " 'CUSTOM_HOPSWORKS_INFERENCE_ENV': 'custom_env_name',\n",
      " 'FEATURES_EMBEDDING_MODEL_ID': 'all-MiniLM-L6-v2',\n",
      " 'HOPSWORKS_API_KEY': SecretStr('**********'),\n",
      " 'OPENAI_API_KEY': SecretStr(''),\n",
      " 'OPENAI_MODEL_ID': 'gpt-4o-mini',\n",
      " 'RANKING_DATASET_VALIDATON_SPLIT_SIZE': 0.1,\n",
      " 'RANKING_EARLY_STOPPING_ROUNDS': 5,\n",
      " 'RANKING_ITERATIONS': 100,\n",
      " 'RANKING_LEARNING_RATE': 0.2,\n",
      " 'RANKING_MODEL_TYPE': 'ranking',\n",
      " 'RANKING_SCALE_POS_WEIGHT': 10,\n",
      " 'RECSYS_DIR': WindowsPath('d:/Projects/ML/personalized-recommendation-sysyem/personalized-recommendation-system/recsys'),\n",
      " 'TWO_TOWER_DATASET_TEST_SPLIT_SIZE': 0.1,\n",
      " 'TWO_TOWER_DATASET_VALIDATON_SPLIT_SIZE': 0.1,\n",
      " 'TWO_TOWER_LEARNING_RATE': 0.001,\n",
      " 'TWO_TOWER_MODEL_BATCH_SIZE': 2048,\n",
      " 'TWO_TOWER_MODEL_EMBEDDING_SIZE': 16,\n",
      " 'TWO_TOWER_NUM_EPOCHS': 5,\n",
      " 'TWO_TOWER_WEIGHT_DECAY': 0.001}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict(settings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from recsys import hopsworks_integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-17 00:14:25.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecsys.hopsworks_integration.feature_store\u001b[0m:\u001b[36mget_feature_store\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mLoging to Hopsworks using HOPSWORKS_API_KEY env var.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-17 00:14:25,164 INFO: Initializing external client\n",
      "2025-03-17 00:14:25,164 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-17 00:14:28,318 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1213659\n"
     ]
    }
   ],
   "source": [
    "project, fs = hopsworks_integration.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the ranking inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|██████████| 4633/4633 elapsed<00:02 remaining<00:00\n",
      "Uploading: 100.000%|██████████| 1149/1149 elapsed<00:01 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://c.app.hopsworks.ai:443/p/1213659/deployments/361479\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment = hopsworks_integration.ranking_serving.HopsworksRankingModel.deploy(\n",
    "    project=project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is ready: 100%|██████████| 6/6 [00:33<00:00,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/1213659/deployments/361476\n",
      "\n",
      "DeployableComponentLogs(instance_name: 'ranking-transformer-00001-deployment-56997df9d6-ww4md', date: datetime.datetime(2025, 3, 16, 19, 55, 9, 996228)) \n",
      "INFO:root:Loading component module...\n",
      "INFO:root:[TransformerModel] Initializing transformer for model: ranking\n",
      "INFO:root:[HopsworksModel] Initializing for model: ranking\n",
      "INFO:hsfs.engine.python:Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai/p/1213659\n",
      "... execution time: 10.983202 seconds\n",
      "INFO:root:Starting KServe server...\n",
      "2025-03-16 14:24:15.228 8 kserve INFO [model_server.py:register_model():363] Registering model: ranking\n",
      "2025-03-16 14:24:15.228 8 kserve INFO [model_server.py:start():298] Setting max asyncio worker threads as 12\n",
      "2025-03-16 14:24:15.228 8 kserve INFO [model_server.py:_serve_rest():244] Starting uvicorn with 1 workers\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions\n",
      "\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
      "\n",
      "2025-03-16 14:24:15.321 uvicorn.error INFO:     Started server process [8]\n",
      "2025-03-16 14:24:15.321 uvicorn.error INFO:     Waiting for application startup.\n",
      "2025-03-16 14:24:15.328 8 kserve INFO [server.py:start():68] Starting gRPC server on [::]:8081\n",
      "2025-03-16 14:24:15.328 uvicorn.error INFO:     Application startup complete.\n",
      "2025-03-16 14:24:15.328 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n",
      "2025-03-16 14:24:20.700 uvicorn.access INFO:     127.0.0.1:55440 8 - \"GET /metrics HTTP/1.1\" 200 OK\n",
      "2025-03-16 14:24:20.701 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0009188652038574219 ['http_status:200', 'http_method:GET', 'time:wall']\n",
      "2025-03-16 14:24:20.701 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0009100000000001884 ['http_status:200', 'http_method:GET', 'time:cpu']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check logs in case of failure\n",
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteDisconnected\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1390\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:294\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRemoteDisconnected\u001b[39m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1390\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:294\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[33m\"\u001b[39m\u001b[33mRemote end closed connection without\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    295\u001b[39m                              \u001b[33m\"\u001b[39m\u001b[33m response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m      1\u001b[39m test_ranking_input = [\n\u001b[32m      2\u001b[39m         {\n\u001b[32m      3\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33md327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m         }\n\u001b[32m     25\u001b[39m     ]\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Test ranking deployment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m ranked_candidates = \u001b[43mranking_deployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_ranking_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Retrieve article ids of the top recommended items\u001b[39;00m\n\u001b[32m     31\u001b[39m recommendations = get_top_recommendations(ranked_candidates[\u001b[33m\"\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m\"\u001b[39m], k=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\deployment.py:213\u001b[39m, in \u001b[36mDeployment.predict\u001b[39m\u001b[34m(self, data, inputs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     data: Union[Dict, InferInput] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    178\u001b[39m     inputs: Union[List, Dict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    179\u001b[39m ):\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send inference requests to the deployment.\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m       One of data or inputs parameters must be set. If both are set, inputs will be ignored.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m \u001b[33;03m        `dict`. Inference response.\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\engine\\serving_engine.py:582\u001b[39m, in \u001b[36mServingEngine.predict\u001b[39m\u001b[34m(self, deployment_instance, data, inputs)\u001b[39m\n\u001b[32m    580\u001b[39m through_hopsworks = serving_tool != PREDICTOR.SERVING_TOOL_KSERVE\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_inference_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrough_hopsworks\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m re:\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    587\u001b[39m         re.response.status_code == RestAPIError.STATUS_CODE_NOT_FOUND\n\u001b[32m    588\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m re.error_code\n\u001b[32m    589\u001b[39m         == ModelServingException.ERROR_CODE_DEPLOYMENT_NOT_RUNNING\n\u001b[32m    590\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\core\\serving_api.py:233\u001b[39m, in \u001b[36mServingApi.send_inference_request\u001b[39m\u001b[34m(self, deployment_instance, data, through_hopsworks)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send inference requests to a deployment with a certain id\u001b[39;00m\n\u001b[32m    221\u001b[39m \n\u001b[32m    222\u001b[39m \u001b[33;03m:param deployment_instance: metadata object of the deployment to be used for the prediction\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m \u001b[33;03m:rtype: Union[Dict, List[InferOutput]]\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deployment_instance.api_protocol == IE.API_PROTOCOL_REST:\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# REST protocol, use hopsworks or istio client\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_inference_request_via_rest_protocol\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrough_hopsworks\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# gRPC protocol, use the deployment grpc channel\u001b[39;00m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_inference_request_via_grpc_protocol(\n\u001b[32m    239\u001b[39m         deployment_instance, data\n\u001b[32m    240\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\core\\serving_api.py:277\u001b[39m, in \u001b[36mServingApi._send_inference_request_via_rest_protocol\u001b[39m\u001b[34m(self, deployment_instance, data, through_hopsworks)\u001b[39m\n\u001b[32m    274\u001b[39m         with_base_path_params = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# send inference request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_base_path_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_base_path_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\decorators.py:45\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\client\\base.py:177\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    174\u001b[39m _logger.debug(\u001b[33m\"\u001b[39m\u001b[33murl:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m hostname_verification:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(url, \u001b[38;5;28mself\u001b[39m._verify))\n\u001b[32m    176\u001b[39m prepped = \u001b[38;5;28mself\u001b[39m._session.prepare_request(request)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m401\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.REST_ENDPOINT \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    180\u001b[39m     \u001b[38;5;66;03m# refresh token and retry request - only on hopsworks\u001b[39;00m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\requests\\adapters.py:682\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    667\u001b[39m     resp = conn.urlopen(\n\u001b[32m    668\u001b[39m         method=request.method,\n\u001b[32m    669\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    678\u001b[39m         chunked=chunked,\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    686\u001b[39m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "test_ranking_input = [\n",
    "        {\n",
    "            \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "            \"month_sin\": 1.2246467991473532e-16,\n",
    "            \"query_emb\": [\n",
    "                0.214135289,\n",
    "                0.571055949,\n",
    "                0.330709577,\n",
    "                -0.225899458,\n",
    "                -0.308674961,\n",
    "                -0.0115124583,\n",
    "                0.0730511621,\n",
    "                -0.495835781,\n",
    "                0.625569344,\n",
    "                -0.0438038409,\n",
    "                0.263472944,\n",
    "                -0.58485353,\n",
    "                -0.307070434,\n",
    "                0.0414443575,\n",
    "                -0.321789205,\n",
    "                0.966559,\n",
    "            ],\n",
    "            \"month_cos\": -1.0,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = ranking_deployment.predict(inputs=test_ranking_input)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/1213659/deployments/361476\n",
      "\n",
      "DeployableComponentLogs(instance_name: 'ranking-transformer-00001-deployment-56997df9d6-6kbnc', date: datetime.datetime(2025, 3, 16, 19, 58, 10, 965935)) \n",
      "INFO:root:Loading component module...\n",
      "INFO:root:[TransformerModel] Initializing transformer for model: ranking\n",
      "INFO:root:[HopsworksModel] Initializing for model: ranking\n",
      "INFO:hsfs.engine.python:Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai/p/1213659\n",
      "... execution time: 10.908188 seconds\n",
      "INFO:root:Starting KServe server...\n",
      "2025-03-16 14:26:36.668 8 kserve INFO [model_server.py:register_model():363] Registering model: ranking\n",
      "2025-03-16 14:26:36.668 8 kserve INFO [model_server.py:start():298] Setting max asyncio worker threads as 12\n",
      "2025-03-16 14:26:36.668 8 kserve INFO [model_server.py:_serve_rest():244] Starting uvicorn with 1 workers\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions\n",
      "\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
      "\n",
      "2025-03-16 14:26:36.721 uvicorn.error INFO:     Started server process [8]\n",
      "2025-03-16 14:26:36.721 uvicorn.error INFO:     Waiting for application startup.\n",
      "2025-03-16 14:26:36.723 8 kserve INFO [server.py:start():68] Starting gRPC server on [::]:8081\n",
      "2025-03-16 14:26:36.723 uvicorn.error INFO:     Application startup complete.\n",
      "2025-03-16 14:26:36.724 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n",
      "INFO:root:Received request via 'v1 protocol'\n",
      "WARNING:py.warnings:VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "\n",
      "WARNING:py.warnings:DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.\n",
      "\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (4.78s) \n",
      "WARNING:py.warnings:VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "\n",
      "INFO:root:✅ Articles Data Retrieved!\n",
      "INFO:root:✅ Inputs are almost ready!\n",
      "INFO:root:✅ Inputs are ready!\n",
      "INFO:httpx:HTTP Request: POST http://ranking-predictor.rec-sys/v1/models/ranking:predict \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Received response via 'v1 protocol'\n",
      "INFO:root:✅ Predictions are ready!\n",
      "2025-03-16 14:27:04.141 kserve.trace requestId: 39ead580-3df3-4dbf-b586-1fc0fafe85ea, preprocess_ms: 8476.555347443, explain_ms: 0, predict_ms: 18910.910129547, postprocess_ms: 0.106096268\n",
      "2025-03-16 14:27:04.142 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 27.389103651046753 ['http_status:200', 'http_method:POST', 'time:wall']\n",
      "2025-03-16 14:27:04.142 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.23436500000000038 ['http_status:200', 'http_method:POST', 'time:cpu']\n",
      "2025-03-16 14:27:11.089 uvicorn.access INFO:     127.0.0.1:38616 8 - \"GET /metrics HTTP/1.1\" 200 OK\n",
      "2025-03-16 14:27:11.090 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0013287067413330078 ['http_status:200', 'http_method:GET', 'time:wall']\n",
      "2025-03-16 14:27:11.090 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0013169999999997906 ['http_status:200', 'http_method:GET', 'time:cpu']\n",
      "INFO:root:Received request via 'v1 protocol'\n",
      "WARNING:py.warnings:DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.\n",
      "\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.05s) \n",
      "INFO:root:✅ Articles Data Retrieved!\n",
      "INFO:root:✅ Inputs are almost ready!\n",
      "INFO:root:✅ Inputs are ready!\n",
      "INFO:httpx:HTTP Request: POST http://ranking-predictor.rec-sys/v1/models/ranking:predict \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Received response via 'v1 protocol'\n",
      "INFO:root:✅ Predictions are ready!\n",
      "2025-03-16 14:28:01.722 kserve.trace requestId: 38ff3359-f3e6-49e5-8d6d-d557e3c14a62, preprocess_ms: 4494.86541748, explain_ms: 0, predict_ms: 15.128135681, postprocess_ms: 0.110626221\n",
      "2025-03-16 14:28:01.722 uvicorn.access INFO:     10.2.3.34:0 8 - \"POST /v1/models/ranking%3Apredict HTTP/1.1\" 200 OK\n",
      "2025-03-16 14:28:01.722 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 4.517374753952026 ['http_status:200', 'http_method:POST', 'time:wall']\n",
      "2025-03-16 14:28:01.722 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.13267700000000016 ['http_status:200', 'http_method:POST', 'time:cpu']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the query inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-17 00:16:21,636 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-17 00:16:21,645 INFO: Initializing external client\n",
      "2025-03-17 00:16:21,645 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-17 00:16:24,471 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1213659\n",
      "2025-03-17 00:16:27,501 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-17 00:16:27,501 INFO: Initializing external client\n",
      "2025-03-17 00:16:27,501 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-17 00:16:30,365 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1213659\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|██████████| 3050/3050 elapsed<00:02 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://c.app.hopsworks.ai:443/p/1213659/deployments/361480\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment = (\n",
    "    hopsworks_integration.two_tower_serving.HopsworksQueryModel.deploy(ranking_model_type=\"ranking\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is ready: 100%|██████████| 6/6 [00:38<00:00,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check logs in case of failure\n",
    "query_model_deployment.get_logs(component=\"transformer\", tail=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"customer_id\": \"d327d0ad9e30085a436933dfbb7f77cf42e38447993a078ed35d93e3fd350ecf\",\n",
    "        \"transaction_date\": \"2022-11-15T12:16:25.330916\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: http://15.235.46.163/v1/models/query:predict). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"error\":\"HTTPError : HTTP 500: \\'month_sin\\'\"}', error code: , error msg: , user msg: \n\n Check the model server logs by using `.get_logs()`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ranked_candidates = \u001b[43mquery_model_deployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Retrieve article ids of the top recommended items\u001b[39;00m\n\u001b[32m      4\u001b[39m recommendations = get_top_recommendations(ranked_candidates[\u001b[33m\"\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m\"\u001b[39m], k=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\deployment.py:213\u001b[39m, in \u001b[36mDeployment.predict\u001b[39m\u001b[34m(self, data, inputs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    177\u001b[39m     data: Union[Dict, InferInput] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    178\u001b[39m     inputs: Union[List, Dict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    179\u001b[39m ):\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send inference requests to the deployment.\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m       One of data or inputs parameters must be set. If both are set, inputs will be ignored.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m \u001b[33;03m        `dict`. Inference response.\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\engine\\serving_engine.py:598\u001b[39m, in \u001b[36mServingEngine.predict\u001b[39m\u001b[34m(self, deployment_instance, data, inputs)\u001b[39m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ModelServingException(\n\u001b[32m    592\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDeployment not created or running. If it is already created, start it by using `.start()` or check its status with .get_state()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    593\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m    595\u001b[39m re.args = (\n\u001b[32m    596\u001b[39m     re.args[\u001b[32m0\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Check the model server logs by using `.get_logs()`\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    597\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m re\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\engine\\serving_engine.py:582\u001b[39m, in \u001b[36mServingEngine.predict\u001b[39m\u001b[34m(self, deployment_instance, data, inputs)\u001b[39m\n\u001b[32m    580\u001b[39m through_hopsworks = serving_tool != PREDICTOR.SERVING_TOOL_KSERVE\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_inference_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrough_hopsworks\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m re:\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    587\u001b[39m         re.response.status_code == RestAPIError.STATUS_CODE_NOT_FOUND\n\u001b[32m    588\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m re.error_code\n\u001b[32m    589\u001b[39m         == ModelServingException.ERROR_CODE_DEPLOYMENT_NOT_RUNNING\n\u001b[32m    590\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\core\\serving_api.py:233\u001b[39m, in \u001b[36mServingApi.send_inference_request\u001b[39m\u001b[34m(self, deployment_instance, data, through_hopsworks)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send inference requests to a deployment with a certain id\u001b[39;00m\n\u001b[32m    221\u001b[39m \n\u001b[32m    222\u001b[39m \u001b[33;03m:param deployment_instance: metadata object of the deployment to be used for the prediction\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m \u001b[33;03m:rtype: Union[Dict, List[InferOutput]]\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deployment_instance.api_protocol == IE.API_PROTOCOL_REST:\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# REST protocol, use hopsworks or istio client\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_inference_request_via_rest_protocol\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthrough_hopsworks\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# gRPC protocol, use the deployment grpc channel\u001b[39;00m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_inference_request_via_grpc_protocol(\n\u001b[32m    239\u001b[39m         deployment_instance, data\n\u001b[32m    240\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\core\\serving_api.py:277\u001b[39m, in \u001b[36mServingApi._send_inference_request_via_rest_protocol\u001b[39m\u001b[34m(self, deployment_instance, data, through_hopsworks)\u001b[39m\n\u001b[32m    274\u001b[39m         with_base_path_params = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# send inference request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_base_path_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_base_path_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\decorators.py:45\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\client\\base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: http://15.235.46.163/v1/models/query:predict). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"error\":\"HTTPError : HTTP 500: \\'month_sin\\'\"}', error code: , error msg: , user msg: \n\n Check the model server logs by using `.get_logs()`"
     ]
    }
   ],
   "source": [
    "ranked_candidates = query_model_deployment.predict(inputs=data)\n",
    "\n",
    "# Retrieve article ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/1213659/deployments/361477\n",
      "\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1213659/serving/361477/logs). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":240027,\"errorMsg\":\"Server logs not available\"}', error code: 240027, error msg: Server logs not available, user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mquery_model_deployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\deployment.py:248\u001b[39m, in \u001b[36mDeployment.get_logs\u001b[39m\u001b[34m(self, component, tail)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m component \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m components:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    243\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComponent \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not valid. Possible values are \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    244\u001b[39m             component, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(components)\n\u001b[32m    245\u001b[39m         )\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m logs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\engine\\serving_engine.py:555\u001b[39m, in \u001b[36mServingEngine.get_logs\u001b[39m\u001b[34m(self, deployment_instance, component, tail)\u001b[39m\n\u001b[32m    547\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDeployment is starting, server logs might not be ready yet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    550\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExplore all the logs and filters in the Kibana logs at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    551\u001b[39m     + deployment_instance.get_url(),\n\u001b[32m    552\u001b[39m     end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    553\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serving_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hsml\\core\\serving_api.py:404\u001b[39m, in \u001b[36mServingApi.get_logs\u001b[39m\u001b[34m(self, deployment_instance, component, tail)\u001b[39m\n\u001b[32m    395\u001b[39m path_params = [\n\u001b[32m    396\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    397\u001b[39m     _client._project_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    400\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    401\u001b[39m ]\n\u001b[32m    402\u001b[39m query_params = {\u001b[33m\"\u001b[39m\u001b[33mcomponent\u001b[39m\u001b[33m\"\u001b[39m: component, \u001b[33m\"\u001b[39m\u001b[33mtail\u001b[39m\u001b[33m\"\u001b[39m: tail}\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m deployable_component_logs.DeployableComponentLogs.from_response_json(\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\decorators.py:45\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ML\\personalized-recommendation-sysyem\\personalized-recommendation-system\\uvenv\\Lib\\site-packages\\hopsworks_common\\client\\base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1213659/serving/361477/logs). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":240027,\"errorMsg\":\"Server logs not available\"}', error code: 240027, error msg: Server logs not available, user msg: "
     ]
    }
   ],
   "source": [
    "query_model_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is stopped: 100%|██████████| 2/2 [00:05<00:00,  2.92s/it]\n",
      "Deployment is stopped: 100%|██████████| 3/3 [00:11<00:00,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.stop()\n",
    "query_model_deployment.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
